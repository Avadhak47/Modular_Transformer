Bootstrap: docker
From: python:3.10-slim

%labels
    Author: Mathematical Reasoning Project
    Version: 1.0
    Description: Transformer model for mathematical reasoning with modular positional encoding

%environment
    export LC_ALL=C
    export LANG=C
    export PYTHONPATH=/workspace:$PYTHONPATH
    export CUDA_VISIBLE_DEVICES=0
    export OMP_NUM_THREADS=1
    export MKL_NUM_THREADS=1

%files
    requirements.txt /workspace/requirements.txt

%post
    # Update package lists and install system dependencies
    apt-get update && apt-get install -y \
        build-essential \
        git \
        wget \
        curl \
        ca-certificates \
        && rm -rf /var/lib/apt/lists/*
    
    # Install Python dependencies
    pip install --no-cache-dir -r /workspace/requirements.txt
    
    # Install CUDA toolkit for V100 compatibility
    # Note: CUDA drivers should be available on the host system
    pip install --no-cache-dir torch==2.1.0+cu118 torchvision==0.16.0+cu118 torchaudio==2.1.0+cu118 --index-url https://download.pytorch.org/whl/cu118
    
    # Create workspace directory
    mkdir -p /workspace
    mkdir -p /workspace/checkpoints
    mkdir -p /workspace/results
    mkdir -p /workspace/logs

%runscript
    python /workspace/main.py "$@"

%startscript
    python /workspace/main.py "$@"

%test
    python -c "import torch; print(f'PyTorch version: {torch.__version__}'); print(f'CUDA available: {torch.cuda.is_available()}')"
    python -c "import transformers; print(f'Transformers version: {transformers.__version__}')"
    python -c "import datasets; print(f'Datasets version: {datasets.__version__}')" 