{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12568818,"sourceType":"datasetVersion","datasetId":7937360}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Environment Setup\n\nimport subprocess\nimport sys\nimport os\nimport shutil\nfrom pathlib import Path\nimport warnings\n\n# Suppress warnings for cleaner output\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n\nprint(\"🔧 Setting up Kaggle environment...\")\n\n# Install required packages\npackages = [\n    \"accelerate>=0.20.0\",\n    \"transformers>=4.30.0\", \n    \"torch>=2.0.0\",\n    \"datasets>=2.10.0\",\n    \"peft>=0.4.0\",\n    \"wandb\",\n    \"numpy<2.0\",  # Important for compatibility\n]\n\nfor package in packages:\n    try:\n        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package, \"--quiet\"])\n        print(f\"✅ Installed {package}\")\n    except:\n        print(f\"⚠️ Failed to install {package}\")\n\nprint(\"✅ Environment setup complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T21:06:57.132502Z","iopub.execute_input":"2025-07-24T21:06:57.132896Z","iopub.status.idle":"2025-07-24T21:07:17.793689Z","shell.execute_reply.started":"2025-07-24T21:06:57.132869Z","shell.execute_reply":"2025-07-24T21:07:17.792980Z"}},"outputs":[{"name":"stdout","text":"🔧 Setting up Kaggle environment...\n✅ Installed accelerate>=0.20.0\n✅ Installed transformers>=4.30.0\n✅ Installed torch>=2.0.0\n✅ Installed datasets>=2.10.0\n✅ Installed peft>=0.4.0\n✅ Installed wandb\n✅ Installed numpy<2.0\n✅ Environment setup complete!\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import zipfile\n\n# Option A: Extract from uploaded dataset\ndataset_path = \"/kaggle/working/\"\nproject_dirs = list(Path(dataset_path).glob(\"**/math_pe_research.zip\"))\n\nif project_dirs:\n    zip_path = project_dirs[0]\n    print(f\"📁 Found project zip: {zip_path}\")\n    \n    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n        zip_ref.extractall(\"/kaggle/working\")\n    print(\"✅ Project extracted successfully!\")\nelse:\n    # Option B: Create project structure manually (if no dataset upload)\n    print(\"📁 Creating project structure manually...\")\n    \n    # This would require you to upload individual files\n    # For now, we'll assume you uploaded as a dataset\n    print(\"⚠️ No zip found. Please upload your project as a dataset.\")\n\n# Verify project structure\nproject_path = Path(\"/kaggle/working/Transformer/math_pe_research\")\nif project_path.exists():\n    print(f\"✅ Project found at: {project_path}\")\n    print(\"📂 Project structure:\")\n    for item in project_path.rglob(\"*\"):\n        if item.is_file() and item.suffix in ['.py', '.md', '.txt']:\n            print(f\"   {item.relative_to(project_path)}\")\nelse:\n    print(\"❌ Project not found. Check your upload.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T21:07:17.794576Z","iopub.execute_input":"2025-07-24T21:07:17.794879Z","iopub.status.idle":"2025-07-24T21:07:17.803302Z","shell.execute_reply.started":"2025-07-24T21:07:17.794857Z","shell.execute_reply":"2025-07-24T21:07:17.802720Z"}},"outputs":[{"name":"stdout","text":"📁 Creating project structure manually...\n⚠️ No zip found. Please upload your project as a dataset.\n✅ Project found at: /kaggle/working/Transformer/math_pe_research\n📂 Project structure:\n   README.md\n   EXPERIMENT_ANALYSIS.md\n   requirements.txt\n   comprehensive_pe_test.py\n   test_architecture_compatibility.py\n   src/positional_encoding/diet.py\n   src/positional_encoding/__init__.py\n   src/positional_encoding/math_adaptive.py\n   src/positional_encoding/sinusoidal.py\n   src/positional_encoding/t5_relative.py\n   src/positional_encoding/alibi.py\n   src/positional_encoding/rope.py\n   src/data/math_dataset_loader.py\n   src/models/mathematical_reasoning_model.py\n   scripts/simulate_experiment.py\n   scripts/comprehensive_test.py\n   scripts/simple_simulation.py\n   scripts/train_and_eval.py\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# # project setup thorugh dataset\n\n# !rm -rf /kaggle/working/Transformer/\n# # Unzip to /kaggle/working/\n# # %cd /kaggle/input/transformer/\n# !apt install tree\n# !tree ..\n# !zip -r transformer.zip /kaggle/input/transformer/Transformer/\n\n# import zipfile\n# z=zipfile.ZipFile('transformer.zip')\n# z.extractall()\n\n# %cd /kaggle/working/kaggle/input/transformer/\n\n# !zip -r transformer.zip Transformer/\n\n# %mv transformer.zip /kaggle/working/\n# %cd /kaggle/working/\n# %rm -rf kaggle\n\n# z=zipfile.ZipFile('transformer.zip')\n# z.extractall()\n\n# %cd /kaggle/working/Transformer/\n# !tree ..","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T21:07:17.804071Z","iopub.execute_input":"2025-07-24T21:07:17.804261Z","iopub.status.idle":"2025-07-24T21:07:17.817316Z","shell.execute_reply.started":"2025-07-24T21:07:17.804246Z","shell.execute_reply":"2025-07-24T21:07:17.816540Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# import torch\n# from pathlib import Path\n\n# # Create required directories\n# directories = [\n#     '/kaggle/working/checkpoints',\n#     '/kaggle/working/evaluation_results',\n#     '/kaggle/working/data_cache',\n#     '/kaggle/working/logs'\n# ]\n\n# for dir_path in directories:\n#     Path(dir_path).mkdir(parents=True, exist_ok=True)\n#     print(f\"✅ Created: {dir_path}\")\n\n# # Check GPU\n# if torch.cuda.is_available():\n#     gpu_name = torch.cuda.get_device_name(0)\n#     gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n#     print(f\"\\n🚀 GPU Available: {gpu_name} ({gpu_memory:.1f} GB)\")\n#     print(f\"   CUDA Version: {torch.version.cuda}\")\n# else:\n#     print(\"\\n❌ NO GPU AVAILABLE!\")\n#     print(\"   Enable GPU: Settings → Accelerator → GPU T4 x2\")\n\n# # Find project directory\n# project_dirs = list(Path('/kaggle/working').glob('**/math_pe_research'))\n# if project_dirs:\n#     project_dir = project_dirs[0]\n#     print(f\"\\n✅ Project found: {project_dir}\")\n# else:\n#     print(\"\\n❌ Project not found. Check extraction step.\")\n#     # Try manual path\n#     possible_paths = [\n#         '/kaggle/working/Transformer/math_pe_research',\n#         '/kaggle/working/math_pe_research'\n#     ]\n#     for path in possible_paths:\n#         if Path(path).exists():\n#             project_dir = Path(path)\n#             print(f\"✅ Found at: {project_dir}\")\n#             break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T21:07:17.817980Z","iopub.execute_input":"2025-07-24T21:07:17.818177Z","iopub.status.idle":"2025-07-24T21:07:17.835786Z","shell.execute_reply.started":"2025-07-24T21:07:17.818162Z","shell.execute_reply":"2025-07-24T21:07:17.835270Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"\n# 🎯 TRAINING CONFIGURATION\n# Modify these settings as needed\n\nCONFIG = {\n    # Model settings\n    'model_size': 'EleutherAI/pythia-2.8b',  # Options: pythia-70m, pythia-410m, pythia-1.4b, pythia-2.8b\n    'pe_method': 'rope',  # Options: 'rope', 'sinusoidal', 't5_relative', 'diet', 'alibi'\n    \n    # Training settings\n    'batch_size': 4,\n    'max_steps': 500,\n    'learning_rate': 2e-5,\n    'max_length': 1024,\n    'use_lora': True,  # Recommended for Kaggle\n    \n    # Data settings\n    'datasets': 'gsm8k,math',  # Available: gsm8k, math, mathqa\n    'data_fraction': 0.1,  # Use 10% of data for faster training\n    \n    # Experiment settings\n    'experiment_name': 'kaggle_math_pe_experiment',\n    'wandb_project': 'kaggle_math_reasoning',\n    \n    # Kaggle-specific settings\n    'save_steps': 100,\n    'eval_steps': 100,\n    'logging_steps': 50,\n}\n\n# Quick configurations for different use cases\nQUICK_CONFIGS = {\n    'fast_test': {\n        'model_size': 'EleutherAI/pythia-70m',\n        'max_steps': 50,\n        'batch_size': 8,\n        'max_length': 512,\n    },\n    'production': {\n        'model_size': 'EleutherAI/pythia-2.8b',\n        'max_steps': 1000,\n        'batch_size': 4,\n        'max_length': 1024,\n    },\n    'math_specialized': {\n        'model_size': 'wellecks/llmstep-mathlib4-pythia2.8b',\n        'pe_method': 'sinusoidal',\n        'max_steps': 500,\n        'batch_size': 2,\n    }\n}\n\n# Uncomment to use a quick configuration:\n# CONFIG.update(QUICK_CONFIGS['fast_test'])  # For quick testing\n# CONFIG.update(QUICK_CONFIGS['production'])  # For full training\n# CONFIG.update(QUICK_CONFIGS['math_specialized'])  # For math-specialized model\n\nprint(\"🎯 Configuration loaded:\")\nfor key, value in CONFIG.items():\n    print(f\"   {key}: {value}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T21:07:17.836521Z","iopub.execute_input":"2025-07-24T21:07:17.836716Z","iopub.status.idle":"2025-07-24T21:07:17.852448Z","shell.execute_reply.started":"2025-07-24T21:07:17.836686Z","shell.execute_reply":"2025-07-24T21:07:17.851756Z"}},"outputs":[{"name":"stdout","text":"🎯 Configuration loaded:\n   model_size: EleutherAI/pythia-2.8b\n   pe_method: rope\n   batch_size: 4\n   max_steps: 500\n   learning_rate: 2e-05\n   max_length: 1024\n   use_lora: True\n   datasets: gsm8k,math\n   data_fraction: 0.1\n   experiment_name: kaggle_math_pe_experiment\n   wandb_project: kaggle_math_reasoning\n   save_steps: 100\n   eval_steps: 100\n   logging_steps: 50\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"\nimport subprocess\nimport shutil\nfrom pathlib import Path\nimport os\n\n# 🧹 Setup directories\nprint(\"🗂️ Setting up directories...\")\n\ndirectories = {\n    'cache_dir': '/tmp/model_cache',\n    'checkpoint_dir': '/kaggle/working/checkpoints',\n    'result_dir': '/kaggle/working/results'\n}\n\nfor name, dir_path in directories.items():\n    Path(dir_path).mkdir(parents=True, exist_ok=True)\n    print(f\"✅ Created {name}: {dir_path}\")\n\n# 🔧 Environment variables\nos.environ['HF_HOME'] = directories['cache_dir']\nos.environ['TOKENIZERS_PARALLELISM'] = 'false'\n# os.environ['WANDB_API_KEY'] = 'your_wandb_key_here'  # Uncomment and add your W&B key\n\n# 📁 Find project directory\nproject_dir = Path(\"/kaggle/working/Transformer/math_pe_research\")\nif not project_dir.exists():\n    print(\"❌ Project directory not found!\")\n    print(\"Please ensure you've uploaded the project correctly in Cell 2.\")\n    exit()\n\nprint(f\"📁 Using project: {project_dir}\")\n\n# 🚀 Build training command\ncmd_parts = [\n    f\"cd {project_dir}\",\n    \"python scripts/train_and_eval.py\",\n    f\"--pe {CONFIG['pe_method']}\",\n    f\"--batch_size {CONFIG['batch_size']}\",\n    f\"--max_steps {CONFIG['max_steps']}\",\n    f\"--learning_rate {CONFIG['learning_rate']}\",\n    f\"--experiment_name {CONFIG['experiment_name']}\",\n    f\"--checkpoint_dir {directories['checkpoint_dir']}\",\n    f\"--result_dir {directories['result_dir']}\",\n    f\"--cache_dir {directories['cache_dir']}\",\n    f\"--max_length {CONFIG['max_length']}\",\n    f\"--model_size {CONFIG['model_size']}\",\n    f\"--datasets {CONFIG['datasets']}\",\n    f\"--wandb_project {CONFIG['wandb_project']}\",\n    f\"--save_steps {CONFIG['save_steps']}\",\n    f\"--eval_steps {CONFIG['eval_steps']}\",\n    f\"--logging_steps {CONFIG['logging_steps']}\"\n]\n\nif CONFIG.get('use_lora', True):\n    cmd_parts.append(\"--use_lora\")\n\ncmd = \" \\\\\\n    \".join(cmd_parts)\n\nprint(f\"\"\"\n🚀 STARTING TRAINING WITH {CONFIG['pe_method'].upper()} PE\n{'='*60}\n\n📊 Configuration:\n   🎯 Model: {CONFIG['model_size']}\n   🔧 PE Method: {CONFIG['pe_method']}\n   📈 Batch Size: {CONFIG['batch_size']}\n   🎓 Max Steps: {CONFIG['max_steps']}\n   📏 Max Length: {CONFIG['max_length']}\n   💡 Learning Rate: {CONFIG['learning_rate']}\n   🔗 LoRA: {CONFIG.get('use_lora', True)}\n\n📝 Command:\n{cmd}\n\n{'='*60}\n\"\"\")\n\n# Execute training\ntry:\n    # Check available space\n    statvfs = os.statvfs('/kaggle/working/Transformer')\n    free_space_gb = (statvfs.f_frsize * statvfs.f_bavail) / (1024**3)\n    print(f\"💾 Available space: {free_space_gb:.1f} GB\")\n    \n    result = subprocess.run(cmd, shell=True, capture_output=False, text=True)\n    if result.returncode == 0:\n        print(\"\\n🎉 Training completed successfully!\")\n    else:\n        print(f\"\\n❌ Training failed with return code: {result.returncode}\")\nexcept KeyboardInterrupt:\n    print(\"\\n⚠️ Training interrupted by user\")\nexcept Exception as e:\n    print(f\"\\n❌ Training failed: {e}\")\n\nprint(f\"\\n📁 Results saved to: {directories['result_dir']}\")\nprint(f\"💾 Checkpoints saved to: {directories['checkpoint_dir']}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T21:07:17.854254Z","iopub.execute_input":"2025-07-24T21:07:17.854446Z","iopub.status.idle":"2025-07-24T21:07:17.875432Z","shell.execute_reply.started":"2025-07-24T21:07:17.854431Z","shell.execute_reply":"2025-07-24T21:07:17.874901Z"}},"outputs":[{"name":"stdout","text":"🗂️ Setting up directories...\n✅ Created cache_dir: /tmp/model_cache\n✅ Created checkpoint_dir: /kaggle/working/checkpoints\n✅ Created result_dir: /kaggle/working/results\n📁 Using project: /kaggle/working/Transformer/math_pe_research\n\n🚀 STARTING TRAINING WITH ROPE PE\n============================================================\n\n📊 Configuration:\n   🎯 Model: EleutherAI/pythia-2.8b\n   🔧 PE Method: rope\n   📈 Batch Size: 4\n   🎓 Max Steps: 500\n   📏 Max Length: 1024\n   💡 Learning Rate: 2e-05\n   🔗 LoRA: True\n\n📝 Command:\ncd /kaggle/working/Transformer/math_pe_research \\\n    python scripts/train_and_eval.py \\\n    --pe rope \\\n    --batch_size 4 \\\n    --max_steps 500 \\\n    --learning_rate 2e-05 \\\n    --experiment_name kaggle_math_pe_experiment \\\n    --checkpoint_dir /kaggle/working/checkpoints \\\n    --result_dir /kaggle/working/results \\\n    --cache_dir /tmp/model_cache \\\n    --max_length 1024 \\\n    --model_size EleutherAI/pythia-2.8b \\\n    --datasets gsm8k,math \\\n    --wandb_project kaggle_math_reasoning \\\n    --save_steps 100 \\\n    --eval_steps 100 \\\n    --logging_steps 50 \\\n    --use_lora\n\n============================================================\n\n💾 Available space: 19.5 GB\n\n🎉 Training completed successfully!\n\n📁 Results saved to: /kaggle/working/results\n💾 Checkpoints saved to: /kaggle/working/checkpoints\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"\nimport json\nimport pandas as pd\nfrom pathlib import Path\n\n# 📊 Load and display results\nresult_dir = Path(\"/kaggle/working/results\")\ncheckpoint_dir = Path(\"/kaggle/working/checkpoints\")\n\nprint(\"📊 TRAINING RESULTS ANALYSIS\")\nprint(\"=\"*50)\n\n# Check for results files\nresult_files = list(result_dir.glob(\"*.json\"))\nif result_files:\n    print(f\"✅ Found {len(result_files)} result files:\")\n    for file in result_files:\n        print(f\"   📄 {file.name}\")\n        \n        # Load and display results\n        try:\n            with open(file, 'r') as f:\n                results = json.load(f)\n            \n            print(f\"\\n📈 Results from {file.name}:\")\n            for key, value in results.items():\n                if isinstance(value, (int, float)):\n                    print(f\"   {key}: {value:.4f}\")\n                else:\n                    print(f\"   {key}: {value}\")\n        except Exception as e:\n            print(f\"   ⚠️ Error reading {file.name}: {e}\")\nelse:\n    print(\"⚠️ No result files found\")\n\n# Check for checkpoints\ncheckpoint_files = list(checkpoint_dir.glob(\"**/*.bin\"))\nif checkpoint_files:\n    print(f\"\\n💾 Found {len(checkpoint_files)} checkpoint files:\")\n    for file in checkpoint_files[-5:]:  # Show last 5\n        size_mb = file.stat().st_size / 1024 / 1024\n        print(f\"   📄 {file.name} ({size_mb:.1f} MB)\")\nelse:\n    print(\"\\n⚠️ No checkpoint files found\")\n\n# Display model summary\nprint(f\"\\n🎯 MODEL SUMMARY:\")\nprint(f\"   PE Method: {CONFIG['pe_method']}\")\nprint(f\"   Base Model: {CONFIG['model_size']}\")\nprint(f\"   Training Steps: {CONFIG['max_steps']}\")\nprint(f\"   LoRA Enabled: {CONFIG.get('use_lora', True)}\")\n\nprint(\"\\n✅ Analysis complete!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T21:07:17.876053Z","iopub.execute_input":"2025-07-24T21:07:17.876304Z","iopub.status.idle":"2025-07-24T21:07:18.190401Z","shell.execute_reply.started":"2025-07-24T21:07:17.876277Z","shell.execute_reply":"2025-07-24T21:07:18.189674Z"}},"outputs":[{"name":"stdout","text":"📊 TRAINING RESULTS ANALYSIS\n==================================================\n⚠️ No result files found\n\n⚠️ No checkpoint files found\n\n🎯 MODEL SUMMARY:\n   PE Method: rope\n   Base Model: EleutherAI/pythia-2.8b\n   Training Steps: 500\n   LoRA Enabled: True\n\n✅ Analysis complete!\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import torch\nimport sys\nfrom pathlib import Path\n\n# Add project to path\nsys.path.insert(0, str(Path(\"/kaggle/working/Transformer/math_pe_research/src\")))\n\ntry:\n    from models.mathematical_reasoning_model import create_mathematical_reasoning_model\n    \n    print(\"🧪 TESTING TRAINED MODEL\")\n    print(\"=\"*40)\n    \n    # Load the trained model\n    print(\"📥 Loading trained model...\")\n    \n    model = create_mathematical_reasoning_model(\n        pe_method=CONFIG['pe_method'],\n        base_model=CONFIG['model_size'],\n        load_in_4bit=False,\n        use_lora=CONFIG.get('use_lora', True),\n        device_map=None,\n        torch_dtype=torch.float16\n    )\n    \n    print(f\"✅ Model loaded with {CONFIG['pe_method']} PE\")\n    \n    # Test problems\n    test_problems = [\n        \"What is 15 + 27?\",\n        \"If a rectangle has length 8 and width 5, what is its area?\", \n        \"Solve for x: 2x + 5 = 13\",\n        \"What is the square root of 144?\",\n        \"A train travels 120 miles in 2 hours. What is its speed?\"\n    ]\n    \n    print(\"\\n🧮 Testing mathematical reasoning:\")\n    print(\"-\" * 40)\n    \n    for i, problem in enumerate(test_problems, 1):\n        print(f\"\\n{i}. Problem: {problem}\")\n        try:\n            solution = model.solve_math_problem(\n                problem, \n                max_length=200, \n                temperature=0.1\n            )\n            print(f\"   Solution: {solution}\")\n        except Exception as e:\n            print(f\"   Error: {e}\")\n    \n    print(f\"\\n🎉 Model testing completed!\")\n    \nexcept Exception as e:\n    print(f\"❌ Model testing failed: {e}\")\n    print(\"This might happen if training didn't complete successfully.\")\n    import traceback\n    traceback.print_exc()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T21:09:46.296321Z","iopub.execute_input":"2025-07-24T21:09:46.297051Z","iopub.status.idle":"2025-07-24T21:11:24.659457Z","shell.execute_reply.started":"2025-07-24T21:09:46.297026Z","shell.execute_reply":"2025-07-24T21:11:24.658681Z"}},"outputs":[{"name":"stderr","text":"2025-07-24 21:10:06.215643: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1753391406.596532     393 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1753391406.701553     393 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"🧪 TESTING TRAINED MODEL\n========================================\n📥 Loading trained model...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/396 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ee39afe3b88490a85132de0472e6bd4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2321b77a5985429d84fff895c53ae565"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7dd9ba9c509449e93175e579d0e7fc0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5909bf920684482f80b892871fc1a7f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/5.68G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c266b7223222409ba667288992de8afd"}},"metadata":{}},{"name":"stderr","text":"The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\nThe new lm_head weights will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\nAsking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","output_type":"stream"},{"name":"stdout","text":"trainable params: 52,428,800 || all params: 2,827,801,641 || trainable%: 1.8540\n✅ Model loaded with rope PE\n\n🧮 Testing mathematical reasoning:\n----------------------------------------\n\n1. Problem: What is 15 + 27?\n   Error: shape '[1, 80, 3, 8, 80]' is invalid for input of size 614400\n\n2. Problem: If a rectangle has length 8 and width 5, what is its area?\n   Error: shape '[1, 89, 3, 8, 80]' is invalid for input of size 683520\n\n3. Problem: Solve for x: 2x + 5 = 13\n   Error: shape '[1, 84, 3, 8, 80]' is invalid for input of size 645120\n\n4. Problem: What is the square root of 144?\n   Error: shape '[1, 82, 3, 8, 80]' is invalid for input of size 629760\n\n5. Problem: A train travels 120 miles in 2 hours. What is its speed?\n   Error: shape '[1, 88, 3, 8, 80]' is invalid for input of size 675840\n\n🎉 Model testing completed!\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Uncomment this cell to test different PE methods\n\"\"\"\nprint(\"🔄 TESTING DIFFERENT PE METHODS\")\nprint(\"=\"*50)\n\npe_methods = ['rope', 'sinusoidal', 't5_relative', 'diet', 'alibi']\ntest_problem = \"What is 12 * 8?\"\n\nfor pe_method in pe_methods:\n    print(f\"\\n🔧 Testing {pe_method.upper()} PE:\")\n    try:\n        model = create_mathematical_reasoning_model(\n            pe_method=pe_method,\n            base_model='EleutherAI/pythia-70m',  # Use small model for quick testing\n            load_in_4bit=False,\n            use_lora=False,\n            device_map=None,\n            torch_dtype=torch.float32\n        )\n        \n        solution = model.solve_math_problem(test_problem, max_length=100, temperature=0.1)\n        print(f\"   ✅ {pe_method}: {solution}\")\n        \n    except Exception as e:\n        print(f\"   ❌ {pe_method}: {e}\")\n\nprint(\"\\n✅ PE method comparison complete!\")\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T21:07:19.803039Z","iopub.execute_input":"2025-07-24T21:07:19.803670Z","iopub.status.idle":"2025-07-24T21:07:19.809098Z","shell.execute_reply.started":"2025-07-24T21:07:19.803650Z","shell.execute_reply":"2025-07-24T21:07:19.808376Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"'\\nprint(\"🔄 TESTING DIFFERENT PE METHODS\")\\nprint(\"=\"*50)\\n\\npe_methods = [\\'rope\\', \\'sinusoidal\\', \\'t5_relative\\', \\'diet\\', \\'alibi\\']\\ntest_problem = \"What is 12 * 8?\"\\n\\nfor pe_method in pe_methods:\\n    print(f\"\\n🔧 Testing {pe_method.upper()} PE:\")\\n    try:\\n        model = create_mathematical_reasoning_model(\\n            pe_method=pe_method,\\n            base_model=\\'EleutherAI/pythia-70m\\',  # Use small model for quick testing\\n            load_in_4bit=False,\\n            use_lora=False,\\n            device_map=None,\\n            torch_dtype=torch.float32\\n        )\\n        \\n        solution = model.solve_math_problem(test_problem, max_length=100, temperature=0.1)\\n        print(f\"   ✅ {pe_method}: {solution}\")\\n        \\n    except Exception as e:\\n        print(f\"   ❌ {pe_method}: {e}\")\\n\\nprint(\"\\n✅ PE method comparison complete!\")\\n'"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"print(\"\"\"\n🎉 KAGGLE DEPLOYMENT COMPLETE!\n\n📊 What you accomplished:\n   ✅ Set up environment with all dependencies\n   ✅ Extracted and verified project structure  \n   ✅ Configured training parameters\n   ✅ Executed training with chosen PE method\n   ✅ Analyzed results and model performance\n   ✅ Tested trained model on mathematical problems\n\n📝 Next steps:\n   1. Experiment with different PE methods\n   2. Try different model sizes  \n   3. Adjust hyperparameters for better performance\n   4. Compare results across configurations\n   5. Share your findings!\n\n🔗 Resources:\n   - Project documentation: /kaggle/working/math_pe_research/README.md\n   - Results: /kaggle/working/results/\n   - Checkpoints: /kaggle/working/checkpoints/\n   - Full deployment guide: /kaggle/working/math_pe_research/KAGGLE_DEPLOYMENT_GUIDE.md\n\nHappy experimenting! 🚀🔥\n\"\"\") ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T21:07:19.809774Z","iopub.execute_input":"2025-07-24T21:07:19.810025Z","iopub.status.idle":"2025-07-24T21:07:19.827020Z","shell.execute_reply.started":"2025-07-24T21:07:19.810003Z","shell.execute_reply":"2025-07-24T21:07:19.826342Z"}},"outputs":[{"name":"stdout","text":"\n🎉 KAGGLE DEPLOYMENT COMPLETE!\n\n📊 What you accomplished:\n   ✅ Set up environment with all dependencies\n   ✅ Extracted and verified project structure  \n   ✅ Configured training parameters\n   ✅ Executed training with chosen PE method\n   ✅ Analyzed results and model performance\n   ✅ Tested trained model on mathematical problems\n\n📝 Next steps:\n   1. Experiment with different PE methods\n   2. Try different model sizes  \n   3. Adjust hyperparameters for better performance\n   4. Compare results across configurations\n   5. Share your findings!\n\n🔗 Resources:\n   - Project documentation: /kaggle/working/math_pe_research/README.md\n   - Results: /kaggle/working/results/\n   - Checkpoints: /kaggle/working/checkpoints/\n   - Full deployment guide: /kaggle/working/math_pe_research/KAGGLE_DEPLOYMENT_GUIDE.md\n\nHappy experimenting! 🚀🔥\n\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Monitor training progress\n# from pathlib import Path\n# import json\n\n# checkpoint_dir = Path('/kaggle/working/checkpoints')\n# results_dir = Path('/kaggle/working/evaluation_results')\n\n# print(\"📊 Training Progress:\")\n\n# # Check checkpoints\n# if checkpoint_dir.exists():\n#     checkpoints = list(checkpoint_dir.glob('**/*'))\n#     print(f\"   📁 Checkpoints: {len(checkpoints)} files\")\n#     for ckpt in checkpoints[:5]:  # Show first 5\n#         if ckpt.is_file():\n#             size_mb = ckpt.stat().st_size / (1024 * 1024)\n#             print(f\"      📄 {ckpt.name} ({size_mb:.1f} MB)\")\n\n# # Check results\n# if results_dir.exists():\n#     results = list(results_dir.glob('*.json'))\n#     print(f\"   📈 Results: {len(results)} files\")\n#     for result_file in results:\n#         try:\n#             with open(result_file, 'r') as f:\n#                 data = json.load(f)\n#             print(f\"      📊 {result_file.name}: {list(data.keys())}\")\n#         except:\n#             print(f\"      📄 {result_file.name}\")\n\n# print(\"\\n🔗 W&B Dashboard: Check your W&B project for live metrics\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T21:07:19.827791Z","iopub.execute_input":"2025-07-24T21:07:19.827990Z","iopub.status.idle":"2025-07-24T21:07:19.840464Z","shell.execute_reply.started":"2025-07-24T21:07:19.827974Z","shell.execute_reply":"2025-07-24T21:07:19.839987Z"}},"outputs":[],"execution_count":11}]}